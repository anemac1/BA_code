{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fba0614",
   "metadata": {},
   "source": [
    "# Concatenate data and creating subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686ce1b",
   "metadata": {},
   "source": [
    "### Step 04\n",
    "### Create Dataset\n",
    "\n",
    "Here we create our complete dataset as well as the subsets.\n",
    "\n",
    "Every CSV file in the specific folder of cleaned data is added. Change the file format or remove files to exclude unwanted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#global variables \n",
    "debug = 0 #for all (1) OR condensed output (0)\n",
    "\n",
    "###### INPUTS\n",
    "path = 'S:/Andreas/FH/Technikum/BA/'  #including slash at the end!\n",
    "get = '40_Prep/'\n",
    "put = '50_Datasets/'\n",
    "#path = r'C:/Users/andre/Data'\n",
    "###### ######\n",
    "\n",
    "# Get data file names\n",
    "temp=path+get\n",
    "all_files = glob.glob(os.path.join(temp, \"*.csv\"))\n",
    "\n",
    "if debug:\n",
    "    print(all_files)\n",
    "\n",
    "print(f'> Fetching data...')\n",
    "# Concatenate all data into one DataFrame\n",
    "all_data = pd.concat((pd.read_csv(file) for file in all_files), ignore_index=False, axis=1)\n",
    "print(f'...done')\n",
    "if debug:\n",
    "    print(all_data.tail())\n",
    "    print(all_data.dtypes)\n",
    "\n",
    "print(f'\\n> Deleting unnecessary columns...')\n",
    "# Dropping all duplicate columns (e.g. UTC)\n",
    "all_data = all_data.loc[:, ~all_data.columns.duplicated()]\n",
    "all_data = all_data.drop('OA_station', axis=1)\n",
    "print(f'...done')\n",
    "\n",
    "print(f'\\n> Converting types and creating new columns...')\n",
    "# Convert all datetimes which are imported as object into datetime64(ns)\n",
    "all_data['UTC'] = pd.to_datetime(all_data['UTC']) #all_data['UTC'].apply(pd.to_datetime)\n",
    "\n",
    "# Make sure these columns are seen as numbers \n",
    "if 'OA_DD' in all_data.columns:\n",
    "    all_data['OA_DD'] = all_data['OA_DD'].astype(float)\n",
    "if 'OA_RF' in all_data.columns:\n",
    "    all_data['OA_RF'] = all_data['OA_RF'].astype(float)\n",
    "if 'OA_FFAM' in all_data.columns:\n",
    "    all_data['OA_FFAM'] = all_data['OA_FFAM']*3.6 # convert to km/h\n",
    "\n",
    "# Create new columns (differences)\n",
    "all_data['CR-HF'] = all_data['CR_T'] - all_data['HF_T']\n",
    "all_data['CC-HF'] = all_data['CC_T'] - all_data['HF_T']\n",
    "all_data['KE-HF'] = all_data['KE_T'] - all_data['HF_T']\n",
    "all_data['KW-HF'] = all_data['KW_T'] - all_data['HF_T']\n",
    "all_data['SR-HF'] = all_data['SR_T'] - all_data['HF_T']\n",
    "\n",
    "print(f'...done')\n",
    "\n",
    "if debug:\n",
    "    print(all_data.tail())\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7aacc0",
   "metadata": {},
   "source": [
    "### (optional) Basic statistics on all float data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd2a0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Describe all data columns with type(s): ['float']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m include \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#['object', 'float', 'int']\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m> Describe all data columns with type(s): \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(include))\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mall_data\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe(include\u001b[38;5;241m=\u001b[39minclude)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))  \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Not possible with Date as datetime:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m#stats = all_data.describe()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mstats.loc['var'] = all_data.var().tolist()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03mprint(skewness_df)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Using describe-method:\n",
    "\n",
    "#example:\n",
    "\n",
    "#percentile list\n",
    "#perc = [.20, .40, .60, .80]\n",
    "#dataframe.describe(perc, include, exclude, datetime_is_numeric)\n",
    "\n",
    "# List of dtypes to include\n",
    "include = ['float'] #['object', 'float', 'int']\n",
    "\n",
    "print(f'> Describe all data columns with type(s): '+str(include))\n",
    "print(all_data.describe(include=include).map(lambda x: f\"{x:0.2f}\"))  \n",
    "\n",
    "\n",
    "# Not possible with Date as datetime:\n",
    "'''\n",
    "#stats = all_data.describe()\n",
    "stats.loc['var'] = all_data.var().tolist()\n",
    "stats.loc['skew'] = all_data.skew().tolist()\n",
    "stats.loc['kurt'] = all_data.kurtosis().tolist()\n",
    "print(stats)\n",
    "#or\n",
    "skewness = all_data.skew()\n",
    "kurtosis = all_data.kurtosis()\n",
    "skewness_df = pd.DataFrame({'skewness':skewness}).T\n",
    "kurtosis_df = pd.DataFrame({'kurtosis':kurtosis}).T\n",
    "print(skewness_df)\n",
    "'''\n",
    "\n",
    "# Alternatives to describe:\n",
    "from summarytools import dfSummary\n",
    "dfSummary(all_data)\n",
    "\n",
    "# Not possible with timestamps\n",
    "'''\n",
    "from scipy.stats import describe\n",
    "describe(all_data, axis=0)\n",
    "'''\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(all_data, title=\"Profiling Report\")\n",
    "display(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa293d69",
   "metadata": {},
   "source": [
    "### (optional) Basic statistics on cross-check of weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98eb39c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OA_TL       OG_T\n",
      "count  359580.00  359580.00\n",
      "mean       11.72      11.53\n",
      "std         8.92       9.22\n",
      "min       -16.10     -16.40\n",
      "25%         4.60       4.10\n",
      "50%        11.30      11.13\n",
      "75%        18.70      18.33\n",
      "max        38.30      38.40\n",
      "\n",
      "\n",
      "         OA_FFAM       OG_W\n",
      "count  359580.00  359580.00\n",
      "mean       11.62      14.94\n",
      "std         7.91      11.60\n",
      "min         0.00       0.00\n",
      "25%         5.40       5.52\n",
      "50%         9.72      12.06\n",
      "75%        16.20      22.03\n",
      "max        70.92     107.30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_658a1 thead>tr>th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_658a1_row0_col0, #T_658a1_row1_col0 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 5%;\n",
       "  max-width: 50px;\n",
       "  min-width: 20px;\n",
       "}\n",
       "#T_658a1_row0_col1, #T_658a1_row1_col1 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 15%;\n",
       "  max-width: 200px;\n",
       "  min-width: 100px;\n",
       "  word-break: break-word;\n",
       "}\n",
       "#T_658a1_row0_col2, #T_658a1_row1_col2 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 30%;\n",
       "  min-width: 100px;\n",
       "}\n",
       "#T_658a1_row0_col3, #T_658a1_row1_col3 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 25%;\n",
       "  min-width: 100px;\n",
       "}\n",
       "#T_658a1_row0_col4, #T_658a1_row1_col4 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 20%;\n",
       "  min-width: 150px;\n",
       "}\n",
       "#T_658a1_row0_col5, #T_658a1_row1_col5 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 10%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_658a1\">\n",
       "  <caption><strong>Data Frame Summary</strong><br><br>Dimensions: 359,580 x 2<br>Duplicates: 93,895</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_658a1_level0_col0\" class=\"col_heading level0 col0\" >No</th>\n",
       "      <th id=\"T_658a1_level0_col1\" class=\"col_heading level0 col1\" >Variable</th>\n",
       "      <th id=\"T_658a1_level0_col2\" class=\"col_heading level0 col2\" >Stats / Values</th>\n",
       "      <th id=\"T_658a1_level0_col3\" class=\"col_heading level0 col3\" >Freqs / (% of Valid)</th>\n",
       "      <th id=\"T_658a1_level0_col4\" class=\"col_heading level0 col4\" >Graph</th>\n",
       "      <th id=\"T_658a1_level0_col5\" class=\"col_heading level0 col5\" >Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_658a1_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_658a1_row0_col1\" class=\"data row0 col1\" ><strong>OA_FFAM</strong><br>[float64]</td>\n",
       "      <td id=\"T_658a1_row0_col2\" class=\"data row0 col2\" >Mean (sd) : 11.6 (7.9)<br>min < med < max:<br>0.0 < 9.7 < 70.9<br>IQR (CV) : 10.8 (1.5)</td>\n",
       "      <td id=\"T_658a1_row0_col3\" class=\"data row0 col3\" >178 distinct values</td>\n",
       "      <td id=\"T_658a1_row0_col4\" class=\"data row0 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAKoAAABGCAYAAABc8A97AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACI0lEQVR4nO3dwWoiQRRG4VsxkTYy3YigOx8hC5c+RB52ttn7LCJIbLEnjiKVzTgEJolaNZ3UX5xvbZcKB+0u9Lbz3huQupvvfgHAJW7PPcA51zOzbuD6e+/9S+CxwF+fhuqc6w2Hw8eyLAchi282m2fn3E9iRaxzn6jdsiwHs9nspaqq3TUL13VdzOfzwWq16poZoSLK2a9+M7Oqqnaj0ehXwPq9gGOAf3AxBQmECgmECgkXnaOGOh6Pd2ZWOudCl2B7C2bWYqhN09wdDoeHyWTS6XQ6V+0YnLC9hZPWQt3v97dFUdxPp9PdeDx+vvZ4trfwVqtf/WZm/X4/dGvLjO0t/MHFFCQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiQQKiS0/ue+GJFzAZgJkJFkQ42dC8BMgLwkG2rMXABmAuQn2VBPIuYCMBMgI1xMQQKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQgKhQkLyv/APxQ2D85JlqNwwOD9ZhsoNg/OTZagn3DA4H1xMQQKhQgKhQgKhQgKhQgKhQkLW21MxGHmZFkJ9ByMv00Oo72DkZXoI9ROMvEwHobaA89v/76JQ67ourl14u90WZmZN0xTL5fL+K4//zudeLBY/Ys5v1+v11jn3ZGZBv/oS9tt7/+F7fgVGkQMvQOQvOAAAAABJRU5ErkJggg==\"></img></td>\n",
       "      <td id=\"T_658a1_row0_col5\" class=\"data row0 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_658a1_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_658a1_row1_col1\" class=\"data row1 col1\" ><strong>OG_W</strong><br>[float64]</td>\n",
       "      <td id=\"T_658a1_row1_col2\" class=\"data row1 col2\" >Mean (sd) : 14.9 (11.6)<br>min < med < max:<br>0.0 < 12.1 < 107.3<br>IQR (CV) : 16.5 (1.3)</td>\n",
       "      <td id=\"T_658a1_row1_col3\" class=\"data row1 col3\" >43,268 distinct values</td>\n",
       "      <td id=\"T_658a1_row1_col4\" class=\"data row1 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAKoAAABGCAYAAABc8A97AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACKUlEQVR4nO3cwWoaURSH8XNqImOEGcSgOx8hC5c+RB+22y4FH0YY4ojTsYpMNrUUkla9t7bzv3y/deaawIdm8Mzxtm0N6LpP//sXAK7xcOkH3H1gZv3A8w9t2zaB1wI//TFUdx+Mx+PPeZ6PQg7fbrev7v6FWBHr0jtqP8/z0WKxaIqi2N9ycFVV2Wq1GpVl2TczQkWUix/9ZmZFUewnk8m3gPMHAdcA73AzBQmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmECglXPS4d6nQ6PZpZ7u6hR7BpBWZ2x1Drun48Ho8vs9ms1+v1blpeccamFZzdLdTD4fCQZdnTfD7fT6fT11uvZ9MKfnXXj34zs+FwGLplxYxNK/iBmylIIFRIIFRIIFRIIFRIIFRIIFRIIFRIIFRIIFRIIFRIIFRIuPtQSozIeVZmWRPS2VBj51mZZU1LZ0ONmWdlljU9nQ31LGKelVnWhHAzBQmECgmECgmECgmECgmECgmECgmECgmECgmECgmECgmd/64/FCsv05JkqKy8TE+SobLyMj1JhnrGyst0cDMFCYQKCYQKCUn/jxqDJ2C7hVA/wBOw3UOoH4h9Ana5XE7Ksnx2923IyxP4e1eFWlVVduvBu90uMzOr6zpbr9dP//L6v/XaIZqmiXo33mw2O3f/amZBX1QI+9627W//5jcj9fgz9lkJlgAAAABJRU5ErkJggg==\"></img></td>\n",
       "      <td id=\"T_658a1_row1_col5\" class=\"data row1 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d069ae6660>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format floating point values\n",
    "#pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Run report on temperature \n",
    "print(all_data[['OA_TL', 'OG_T']].describe().map(lambda x: f\"{x:0.2f}\"))\n",
    "dfSummary(all_data[['OA_TL', 'OG_T']])\n",
    "print('\\n')\n",
    "\n",
    "# Run report on wind (speed)\n",
    "print(all_data[['OA_FFAM', 'OG_W']].describe().map(lambda x: f\"{x:0.2f}\"))\n",
    "dfSummary(all_data[['OA_FFAM', 'OG_W']])\n",
    "\n",
    "# Check also sunshine vs. brightness?\n",
    "#print(all_data[['OA_SO', 'OG_B']].describe().applymap(lambda x: f\"{x:0.2f}\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9677d57",
   "metadata": {},
   "source": [
    "#### Exkursus:\n",
    "**Out of personal experience**, the room `CR (Corridor - reading corner)` might be the room where least changes in temperature due to sealings malfunction might occur (as there is no window to open). An installed controlled living room ventilation system running 365 days/year makes manual ventilation unnecessary and in practice windows are opened once a year for cleaning.\n",
    "This room (and its window) is quite remote from the wind (predominantly blowing from the North-West) due to its location towards the East. Thats why the differences between this room and the most used and exposed to wind and outside temperatures part of the house  `HF (Hall - front door)` - the front door of the building - is used for analysis.\n",
    "\n",
    "Alternatives - as there are windows to open but quite far away from the sensor:\n",
    "> `KE (Kids East)` \\\n",
    "> `KW (Kids West)` \\\n",
    "> `SR (Sleeping room)` \\\n",
    "> `CC (Corridor - closet)` might be too near to bathroom, where temperature levels may be strongly intertwined with usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9e5d4",
   "metadata": {},
   "source": [
    "### Step 05\n",
    "### Feature engineering/encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229e581-5651-4a7a-866c-328719a11292",
   "metadata": {},
   "source": [
    "#### #01 - Finding Coldest months for subset \"cold season\"\n",
    "In order to find subsets of the total dataset with similar features, data shall be clustered/binned into categories. With time series analysis on expected and over the long run realized weather data, timestamps are a useful way of categorisation as seasonal patterns should emerge.  \n",
    "\n",
    "The potential problem with sealings is found easier, if the temperature difference between indoor and outside is highest. This is accomplished by creating a category \"month\" and calculating the mean of outside temperature for every of these 12 months which helps filtering data. The three coldest months in the year were then chosen for this subset. In order to validate this categorisation also a clustering for coldest days was performed. An average daily outside temperature below 5Â°C (with few readings slightly above this value) was seen after day 326 and before day 67 (of the year), confirming that this timespan selection is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "054d14d3-b749-47da-990c-bcd4d7995e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         OA_TL\n",
      "Mth           \n",
      "11    6.264059\n",
      "12    2.522248\n",
      "1     1.352080\n",
      "2     3.606060\n",
      "3     6.694790\n",
      "4    10.917057\n",
      "5    15.198115\n",
      "6    21.077391\n",
      "7    22.007012\n",
      "8    21.909604\n",
      "9    16.769162\n",
      "10   11.892156\n"
     ]
    }
   ],
   "source": [
    "# Check if full dataset\n",
    "t = range(all_data.index.size)\n",
    "t \n",
    "\n",
    "###### outside temperature\n",
    "###### INPUTS\n",
    "c = 32      #32 = oa_tl, 38 = og_t\n",
    "###### ######\n",
    "\n",
    "cn = all_data.iloc[:, c].name\n",
    "# Updating dataframe to have only one column as all other columns are of no use for us at the moment \n",
    "# using .to_frame() to convert pandas series into dataframe.\n",
    "#all_data[cn] = pd.to_numeric(all_data[cn])\n",
    "df_short = all_data[cn].to_frame()\n",
    "\n",
    "# Sset date column as index\n",
    "df_short = df_short.set_index(pd.DatetimeIndex(pd.to_datetime(all_data.iloc[:, 0])))\n",
    "df_short.sort_index(inplace=True)\n",
    "\n",
    "#'''\n",
    "# Copy df to use it for validation below\n",
    "df_short_day = df_short\n",
    "\n",
    "# Create mean temperature per month (building a category on the index)\n",
    "df_short['Mth'] = df_short.index.month.astype('category')\n",
    "print(df_short.groupby('Mth', sort=False, observed=False).mean())\n",
    "\n",
    "'''\n",
    "# Validate Mth with check of days below approx. 5 degrees (\"toggle\" multiline comment in line 20 and 28)\n",
    "df_short_day['Day'] = df_short_day.index.dayofyear.astype('category')\n",
    "#pd.set_option('display.max_rows', df_short_day.shape[0]+1)\n",
    "print(df_short_day.groupby('Day', sort=False, observed=False).mean().head(365))\n",
    "'''\n",
    "# Add feature to dataframe\n",
    "###### INPUTS - Based on Datetime only\n",
    "mth_start = 12\n",
    "mth_end = 2\n",
    "###### ######\n",
    "all_data['CS'] = np.where((all_data['UTC'].dt.month >= mth_start) | (all_data['UTC'].dt.month <= mth_end), 1, 0)\n",
    "all_data['CS'] = all_data['CS'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5cac3-a3e7-490d-b20c-7264689fae3b",
   "metadata": {},
   "source": [
    "#### #02 - Finding the windiest months\n",
    "The same methodology used for finding the coldest months was applied to wind also. Hypothesis suggests that stronger wind puts more pressure to the front door increasing potential airleakages. \n",
    "\n",
    "Average wind speeds are highest between December and April in the used data set. But MoM (month on month) differences of average wind speed and wind direction do not change very much. Additionally this subset filtered on wind contains the coldest months, too. That's why further use of this potential subset was dismissed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2f12f4d-d41d-4b6c-affe-45ce55f3d62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          OG_W\n",
      "Mth           \n",
      "11   14.913922\n",
      "12   16.834112\n",
      "1    16.709767\n",
      "2    17.800649\n",
      "3    16.206456\n",
      "4    17.045428\n",
      "5    15.095884\n",
      "6    13.390035\n",
      "7    12.813406\n",
      "8    11.898219\n",
      "9    12.215368\n",
      "10   14.231702\n"
     ]
    }
   ],
   "source": [
    "# Check if full dataset\n",
    "t = range(all_data.index.size)\n",
    "t \n",
    "\n",
    "# Wind\n",
    "###### INPUTS\n",
    "c = 40     #OG_W = 40; FFAM (m/s) = 24; DD = 22\n",
    "###### ######\n",
    "cn = all_data.iloc[:, c].name\n",
    "# Updating dataFrame to have only one column as all other columns are of no use for us at the moment \n",
    "# Using .to_frame() to convert pandas series into dataframe.\n",
    "#all_data[cn] = pd.to_numeric(all_data[cn])\n",
    "df_short = all_data[cn].to_frame()\n",
    "\n",
    "# Set date column as index\n",
    "df_short = df_short.set_index(pd.DatetimeIndex(pd.to_datetime(all_data.iloc[:, 0])))\n",
    "df_short.sort_index(inplace=True)\n",
    "\n",
    "# Building a category on the index\n",
    "df_short['Mth'] = df_short.index.month.astype('category') \n",
    "print(df_short.groupby('Mth', sort=False, observed=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46ae44-e2ba-42f4-81f0-f6277c22aa9a",
   "metadata": {},
   "source": [
    "#### #03 - (optional) Creating additional columns\n",
    "Not a basic necessary step, but potentially useful for future in-depth analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bbcfe91-5225-4ff7-a45b-2b99a91f26b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating additional columns...\n",
      "...done\n"
     ]
    }
   ],
   "source": [
    "print(f'> Creating additional columns...')\n",
    "all_data['OG-OA'] = all_data['OG_T'] - all_data['OA_TL']\n",
    "all_data['OG-OA_W'] = all_data['OG_W'] - all_data['OA_FFAM']\n",
    "print(f'...done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32051bcc-b477-44da-8481-5059f2a6206c",
   "metadata": {},
   "source": [
    "#### #04 - Difference normalization and adding column\n",
    "Observed temperature differences of specific locations in the house serve as an indicator for airtightness. To find a trend more easily (at a later stage), the mean of difference in the first year of observations shall serve as the \"neutral level\" to start from. Therefore we calculate this number and add/subtract it from every observation in the datapoint, creating a new column \"..._n\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602d11c7-0b1b-4968-8e59-bc42bd5ae29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG-OA_W    4.440702\n",
      "dtype: float64\n",
      "> New column \"OG-OA_W_n\" added!\n",
      "0         2.761298\n",
      "1        -0.153702\n",
      "2         4.470298\n",
      "3         6.315298\n",
      "4         5.828298\n",
      "            ...   \n",
      "359575   -0.556302\n",
      "359576    9.487698\n",
      "359577    6.071298\n",
      "359578    6.179298\n",
      "359579    5.035298\n",
      "Name: OG-OA_W_n, Length: 359580, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "###### INPUTS for all difference columns, e.g. KE-HF\n",
    "c = 55\n",
    "period = 52596\n",
    "###### ######\n",
    "\n",
    "cn = all_data.iloc[:, c].name\n",
    "# Updating dataFrame to have only one column as all other columns are of no use for us at the moment \n",
    "# Using .to_frame() to convert pandas series into dataframe.\n",
    "all_data[cn] = pd.to_numeric(all_data[cn])\n",
    "df_short = all_data[cn].to_frame()\n",
    "\n",
    "m = df_short.head(period).mean()\n",
    "print(m)\n",
    "cnn = cn + '_n'\n",
    "all_data[cnn] = all_data[cn].apply(lambda x: x - m)\n",
    "print(f'> New column \"'+cnn+'\" added!')\n",
    "print(all_data[cnn])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae2d8f-80ee-40a7-bfcb-d1c98a81ddd7",
   "metadata": {},
   "source": [
    "#### Excursus: List of columns if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789410de-03bd-45db-9bec-6f3d2fe872d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns\n",
    "#i = 0\n",
    "#for col in all_data.columns:\n",
    "#    print(str(i)+': '+col)\n",
    "#    i += 1\n",
    "\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601277b-4bad-4fd2-b408-62c8b36855ad",
   "metadata": {},
   "source": [
    "### Step 06 \n",
    "### Creating subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "158abc5a-6cbf-45ec-a775-341a9c65c920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating subsets:\n",
      "Subset \"co\" created with 32884 rows\n",
      "Subset \"cs\" created with 90864 rows\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create subsets\n",
    "print(f'> Creating subsets:')\n",
    "\n",
    "###### INPUTS - Various Parameters\n",
    "#wind direction in degrees, speed, temperature\n",
    "wind_h = 320.0 #max, lower than...\n",
    "wind_l = 220.0 #min, higher than...\n",
    "windspeed_l = 0.0 #min, higher than in m/s\n",
    "temp_h = 5.0 #max, lower than...\n",
    "# taking out missing data \n",
    "time_l = datetime(2018, 12, 1, 0, 10) #'12/01/2018 00:10'\n",
    "time_h = datetime(2018, 11, 18, 9, 30) #'11/18/2018 09:30'\n",
    "###### ######\n",
    "\n",
    "'''\n",
    "df_co = all_data[(all_data['OA_DD'] >= wind_l) & (all_data['OA_DD'] <= wind_h) & (all_data['OA_FFAM'] >= windspeed_l) & (all_data['OA_TL'] <= temp_h) & ((all_data.iloc[:, 0] <= time_h) | (all_data.iloc[:, 0] >= time_l))]\n",
    "print(f'Subset \"co\" created with ' +str(df_co.shape[0])+ ' rows')\n",
    "if debug:\n",
    "    print(f'Describe Subset \"co\" data...')\n",
    "    print(df_co.describe(include=include))\n",
    "\n",
    "#subset1a = all_data[(all_data['AG_Temp'] <= temp_h)]\n",
    "#print(f'Subset 1a created with ' +str(subset1a.shape[0])+ ' rows')\n",
    "'''\n",
    "df_cs = all_data[(all_data.iloc[:, 0].dt.month >= mth_start) | (all_data.iloc[:, 0].dt.month <= mth_end)] \n",
    "print(f'Subset \"cs\" created with ' +str(df_cs.shape[0])+ ' rows')\n",
    "if debug:\n",
    "    print(f'Describe Subset \"cs\" data...')\n",
    "    print(df_cs.describe(include=include))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a89b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 90864 entries, 2357 to 330820\n",
      "Data columns (total 63 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   UTC            90864 non-null  datetime64[ns]\n",
      " 1   BA_T           90864 non-null  float64       \n",
      " 2   BA_T_FLAG      90864 non-null  int64         \n",
      " 3   CC_T           90864 non-null  float64       \n",
      " 4   CC_T_FLAG      90864 non-null  int64         \n",
      " 5   CR_T           90864 non-null  float64       \n",
      " 6   CR_T_FLAG      90864 non-null  int64         \n",
      " 7   DR_T           90864 non-null  float64       \n",
      " 8   DR_T_FLAG      90864 non-null  int64         \n",
      " 9   HB_T           90864 non-null  float64       \n",
      " 10  HB_T_FLAG      90864 non-null  int64         \n",
      " 11  HF_T           90864 non-null  float64       \n",
      " 12  HF_T_FLAG      90864 non-null  int64         \n",
      " 13  KE_T           90864 non-null  float64       \n",
      " 14  KE_T_FLAG      90864 non-null  int64         \n",
      " 15  KW_T           90864 non-null  float64       \n",
      " 16  KW_T_FLAG      90864 non-null  int64         \n",
      " 17  LA_T           90864 non-null  float64       \n",
      " 18  LA_T_FLAG      90864 non-null  int64         \n",
      " 19  LR_T           90864 non-null  float64       \n",
      " 20  LR_T_FLAG      90864 non-null  int64         \n",
      " 21  OA_time        90864 non-null  int64         \n",
      " 22  OA_DD          90864 non-null  float64       \n",
      " 23  OA_DD_FLAG     90864 non-null  int64         \n",
      " 24  OA_FFAM        90864 non-null  float64       \n",
      " 25  OA_FFAM_FLAG   90864 non-null  int64         \n",
      " 26  OA_FFX         90864 non-null  float64       \n",
      " 27  OA_FFX_FLAG    90864 non-null  int64         \n",
      " 28  OA_P           90864 non-null  float64       \n",
      " 29  OA_P_FLAG      90864 non-null  int64         \n",
      " 30  OA_RF          90864 non-null  float64       \n",
      " 31  OA_RF_FLAG     90864 non-null  int64         \n",
      " 32  OA_TL          90864 non-null  float64       \n",
      " 33  OA_TL_FLAG     90864 non-null  int64         \n",
      " 34  OA_ZEITX       90864 non-null  float64       \n",
      " 35  OA_ZEITX_FLAG  90864 non-null  int64         \n",
      " 36  OG_B           90864 non-null  float64       \n",
      " 37  OG_B_FLAG      90864 non-null  int64         \n",
      " 38  OG_T           90864 non-null  float64       \n",
      " 39  OG_T_FLAG      90864 non-null  int64         \n",
      " 40  OG_W           90864 non-null  float64       \n",
      " 41  OG_W_FLAG      90864 non-null  int64         \n",
      " 42  SR_T           90864 non-null  float64       \n",
      " 43  SR_T_FLAG      90864 non-null  int64         \n",
      " 44  UR_T           90864 non-null  float64       \n",
      " 45  UR_T_FLAG      90864 non-null  int64         \n",
      " 46  WR_T           90864 non-null  float64       \n",
      " 47  WR_T_FLAG      90864 non-null  int64         \n",
      " 48  CR-HF          90864 non-null  float64       \n",
      " 49  CC-HF          90864 non-null  float64       \n",
      " 50  KE-HF          90864 non-null  float64       \n",
      " 51  KW-HF          90864 non-null  float64       \n",
      " 52  SR-HF          90864 non-null  float64       \n",
      " 53  CS             90864 non-null  int32         \n",
      " 54  OG-OA          90864 non-null  float64       \n",
      " 55  OG-OA_W        90864 non-null  float64       \n",
      " 56  CR-HF_n        90864 non-null  float64       \n",
      " 57  CC-HF_n        90864 non-null  float64       \n",
      " 58  KE-HF_n        90864 non-null  float64       \n",
      " 59  KW-HF_n        90864 non-null  float64       \n",
      " 60  SR-HF_n        90864 non-null  float64       \n",
      " 61  OG-OA_n        90864 non-null  float64       \n",
      " 62  OG-OA_W_n      90864 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(37), int32(1), int64(24)\n",
      "memory usage: 44.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_cs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fac9e6-49f6-42c7-aa8e-442ec5988d74",
   "metadata": {},
   "source": [
    "### Save total or subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cf845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch between datasets\n",
    "df = all_data  #all_data  #df_co  #df_cs\n",
    "\n",
    "# Potentially reduce columns\n",
    "#df = df.loc[:,~df.columns.str.startswith('OA')]  #with copy\n",
    "#df.drop(list(df.filter(regex = '_FLAG')), axis = 1, inplace = True) #without copy\n",
    "\n",
    "\n",
    "if (len(df.index) < 359580):\n",
    "    file = path+put+'df_cx_'+str(df.shape[0])+'.csv'\n",
    "    df.to_csv(file, sep=',', index=False, encoding='utf-8')\n",
    "else:\n",
    "    file = path+put+'df_al.csv'\n",
    "    all_data.to_csv(file, sep=',', index=False, encoding='utf-8')\n",
    "print(f'> Export to \\'' + file + '\\' successful')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
